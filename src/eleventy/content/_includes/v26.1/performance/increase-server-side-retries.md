- [Send statements in transactions as a single batch]({% link "{{ page.version.version }}/transactions.md" %}#batched-statements). Batching allows CockroachDB to [automatically retry]({% link "{{ page.version.version }}/transactions.md" %}#automatic-retries) a transaction when [previous reads are invalidated]({% link "{{ page.version.version }}/architecture/transaction-layer.md" %}#read-refreshing) at a [pushed timestamp]({% link "{{ page.version.version }}/architecture/transaction-layer.md" %}#timestamp-cache). When a multi-statement transaction is not batched, and takes more than a single round trip, CockroachDB cannot automatically retry the transaction. For an example showing how to break up large transactions in an application, see [Break up large transactions into smaller units of work](build-a-python-app-with-cockroachdb-sqlalchemy.html#break-up-large-transactions-into-smaller-units-of-work). 

- Limit the size of the result sets of your transactions to under 16KB, so that CockroachDB is more likely to [automatically retry]({% link "{{ page.version.version }}/transactions.md" %}#automatic-retries) when [previous reads are invalidated]({% link "{{ page.version.version }}/architecture/transaction-layer.md" %}#read-refreshing) at a [pushed timestamp]({% link "{{ page.version.version }}/architecture/transaction-layer.md" %}#timestamp-cache). When a transaction returns a result set over 16KB, even if that transaction has been sent as a single batch, CockroachDB cannot automatically retry the transaction. You can change the results buffer size for all new sessions using the `sql.defaults.results_buffer.size` [cluster setting](cluster-settings.html), or for a specific session using the `results_buffer_size` [connection parameter]({% link "{{page.version.version}}/connection-parameters.md" %}#additional-connection-parameters).
