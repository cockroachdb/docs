---
title: Technical Advisory 144650
advisory: A-144650
summary: In rare cases, some bulk data write operations could succeed without ingesting all expected data.
toc: true
affected_versions: v23.2.0 to v23.2.23, v24.1.0 to v24.1.16, all versions of v24.2, v24.3.0 to v24.3.10, v25.1.0 to v25.1.4, testing versions of v25.2 through v25.2.0-beta.1
advisory_date: 2025-05-05
docs_area: releases
---

Publication date: {{ page.advisory_date | date: "%B %e, %Y" }}

## Description

In versions of CockroachDB v23.2.0 to v23.2.23, v24.1.0 to v24.1.16, all versions of v24.2, v24.3.0 to v24.3.10, v25.1.0 to v25.1.4, and testing versions of v25.2 through v25.2.0-beta.1, certain bulk data write operations could succeed without ingesting all expected data. Only the following operations are affected:

- Import
- MOLT Fetch (Without Verify)
- Physical Cluster Replication
- Create Table As (CTAS)
- Materialized View Refreshes

Other bulk data write operations are not affected. Restore is unaffected because it never uses the rare code path affected by this bug. Index backfill schema changes avoid this problem because of post-ingestion index validation, which will fail the index creation if there is any missing data.

Bulk data write operations have two code paths for flushing data to disk. One path is common, and one is rare. This issue only impacts the rare code path, and presents due to a problem where errors (such as lack of disk space or node unavailability) were incorrectly handled and not properly retried, leading to improper success of the bulk data write operation. This issue can only occur if no other errors (such as lack of disk space or node unavailability) occur during the bulk operation outside of the rare code path, since other errors would cause the operation to retry or rollback.

Specific steps to identify and mitigate affected operations are described in the [Mitigation](#mitigation) section below.

## Statement

This issue is resolved in CockroachDB by PR #144646 which disables the rare (async flush) code path for bulk write operations.

The fix has been applied to maintenance releases of CockroachDB v23.2.24, v24.1.17, v24.3.11, v25.1.5, and the testing version of v25.2 v25.2.0-beta.2.

This issue is tracked publicly by #144650.

## Mitigation

Users of CockroachDB v23.2.0 to v23.2.23, v24.1.0 to v24.1.16, all versions of v24.2, v24.3.0 to v24.3.10, v25.1.0 to v25.1.4, and testing versions of v25.2 through v25.2.0-beta.1 are encouraged to upgrade to v23.2.24, v24.1.17, v24.3.11, v25.1.5, the testing version of v25.2 v25.2.0-beta.2, or a later version. This technical advisory only affects the following operations: Import, MOLT Fetch (Without Verify), Physical Cluster Replication, Create Table As (CTAS), and Materialized View Refreshes. Users that do not use the above listed operations are not affected. 

Users on affected versions can determine whether they may have encountered the problem by running the script we have provided here, which examines the CockroachDB logs for the presence of certain log lines that indicate specific jobs may have been affected. The existence of these log lines as reported by the script does not guarantee that an operation was affected, but any potentially affected jobs identified by the script should be validated. Specific steps to validate each operation and fix problems are described below.

If the script does not find the applicable log lines, your cluster was not affected by the bug during the log retention period.

### Import

The script above might indicate that an import job was affected. Import jobs affected by the problem could be missing rows that were present in the source data. To check whether a suspected import job was affected, the number of rows imported must be compared with the number of rows in the source data.

There are several ways to check the number of rows imported into a table.

1. If the output of the IMPORT statement showed the expected number of rows, the import was unaffected.

1. After a successful import, there should be a RecoveryEvent logged to the TELEMETRY logging channel with "RecoveryType": "import_job". If NumRows from this event shows the expected number of rows, the import was unaffected.

1. If the previous two steps do not show the correct number of rows, or are not possible due to the time elapsed since the import, then RESTORE â€¦ AS OF SYSTEM TIME can be used to reconstruct the table as it was immediately after the import finished. A `SELECT count(*)` query can be used to count the rows in the restored table. (If the table contained some rows before the import, then a second RESTORE AS OF SYSTEM TIME must be used to reconstruct the table as it was immediately before the import started, and this count must be subtracted from the first count.) If this count shows the expected number of rows, the import was unaffected.

If a discrepancy is found, mitigation steps depend on whether a primary index or secondary index is affected. If the primary index is affected, the IMPORT should be run a second time (after upgrading to a version with the fix). The two imported datasets can be compared with a join, and any missing rows must be added manually.

If the primary index is unaffected, but a secondary index is affected, the secondary index can be dropped and re-created.

### MOLT Fetch

As recommended in our documentation, a run of MOLT Fetch should be followed by a run of MOLT Verify  to ensure that all data on the target side matches the data on the source side.  If you ran Verify after your Fetch completed, and it ran successfully, then you are not subject to this issue.  If you didn't run Verify following Fetch, then you could leverage any exported files that exist in your cloud storage bucket and follow the IMPORT case described above.

### Physical Cluster Replication

After upgrading both clusters to the latest patch release with the fix, verify the data on the source and destination clusters are the same as of a replicated time, using our fingerprint tooling. If a discrepancy is found, the user should tear down their PCR stream (i.e. drop the replicating tenant), and restart the PCR stream from scratch. We encourage users to reach out to support to work through these steps if a fingerprint mismatch is found.

### Create Table As Select (CTAS)

Similar to IMPORT, the number of rows in the created table can be used as an indication of whether the CTAS operation was successful. You can compare the number of rows between the created table and the creation query to verify that all rows are present. 

If a discrepancy is found, you can drop the affected table and re-run the CTAS operation after upgrading to a version with the fix.

### Materialized View Refreshes

Materialized view refreshes can be validated in a similar manner to CTAS by comparing the number of rows in the materialized view vs the source data. The best remediation is to refresh the materialized views to make sure they have the most up to date data. 

## Impact

In rare cases, some bulk data write operations could succeed without ingesting all expected data. Versions affected include v23.2.0 to v23.2.23, v24.1.0 to v24.1.16, all versions of v24.2, v24.3.0 to v24.3.10, v25.1.0 to v25.1.4, and testing versions of v25.2 through v25.2.0-beta.1.

Reach out to our support team if more information or assistance is needed.