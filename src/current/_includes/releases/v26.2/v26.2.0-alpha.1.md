## v26.2.0-alpha.1

Release Date: March 11, 2026

{% include releases/new-release-downloads-docker-image.md release=include.release %}

<h3 id="v26-2-0-alpha-1-backward-incompatible-changes">Backward-incompatible changes</h3>

- The `incremental_location`
  option has been removed from `BACKUP` and `CREATE SCHEDULE FOR BACKUP`. [#159189][#159189]
- The `incremental_location`
  option has been removed from `SHOW BACKUP` and `RESTORE`. [#160416][#160416]
- The default value of
  `sql.stats.automatic_full_concurrency_limit` (which determines the
  maximum number of automatic full concurrent statistic collection) has
  been increased from 1 to number of vCPUs divided by 2 (e.g. 4 vCPU nodes
  will have the value of 2). [#161806][#161806]
- The `TG_ARGV` trigger function parameter now uses 0-based indexing to match PostgreSQL behavior. Previously, `TG_ARGV[1]` returned the first argument; now `TG_ARGV[0]` returns the first argument and `TG_ARGV[1]` returns the second argument. Additionally, usage of `TG_ARGV` no longer requires setting the `allow_create_trigger_function_with_argv_references` session variable. [#161925][#161925]
- Creating or altering a
  changefeed or kafka/pubsub external connection now returns an error
  when the `topic_name` query parameter is explicitly set to an empty
  string in the sink URI, rather than silently falling back to using the
  table name as the topic name. Existing changefeeds with an empty
  `topic_name` are not affected. [#164225][#164225]

<h3 id="v26-2-0-alpha-1-security-updates">Security updates</h3>

- LDAP authentication for the DB Console now
  supports automatic user provisioning. When the cluster setting
  `security.provisioning.ldap.enabled` is set to true, users who authenticate
  successfully via LDAP will be automatically created in CockroachDB if they do
  not already exist. [#163199][#163199]

<h3 id="v26-2-0-alpha-1-general-changes">General changes</h3>

- Changefeeds now support the `partition_alg`
  option for specifying a kafka partitioning algorithm. Currently `fnv-1a`
  (default) and `murmur2` are supported. The option is only valid on kafka
  v2 sinks. This is protected by the cluster setting
  `changefeed.partition_alg.enabled`. An example usage: `SET CLUSTER SETTING
  changefeed.partition_alg.enabled=true; CREATE CHANGEFEED ... INTO
  'kafka://...' WITH partition_alg='murmur2';` Note that if a changefeed is
  created using the murmur2 algorithm, and then the cluster setting is
  disabled, the changefeed will continue using the murmur2 algorithm
  unless the changefeed is altered to use a differed `partition_alg`. [#161265][#161265]

<h3 id="v26-2-0-alpha-1-{{-site.data.products.enterprise-}}-edition-changes">{{ site.data.products.enterprise }} edition changes</h3>

- Added a new cluster setting, `security.provisioning.oidc.enabled`, to allow automatic provisioning of users when they log in for the first time via OIDC. When enabled, a new user will be created in CockroachDB upon their first successful OIDC authentication. This feature is disabled by default. [#159787][#159787]
- LDAP authentication for the DB Console now additionally supports role-based access control (RBAC) through LDAP group membership.
  
  To use this feature, an administrator must first create roles in CockroachDB with names that match the Common Names (CN) of their LDAP groups. These roles should then be granted the desired privileges for DB Console access.
  
  When a user who is a member of a corresponding LDAP group logs into the DB Console, they will be automatically granted the role and its associated privileges, creating consistent behavior with SQL client connections. [#162302][#162302]

<h3 id="v26-2-0-alpha-1-sql-language-changes">SQL language changes</h3>

- Fixed a bug that caused a routine with an `INSERT` statement to unnecessarily block dropping a hash-sharded index or computed column on the target table. This fix applies only to newly created routines. In releases prior to v25.3, the fix must be enabled by setting the session variable `use_improved_routine_dependency_tracking` to `on`. [#146250][#146250]
- The output of `EXPLAIN [ANALYZE]` in
  non-`VERBOSE` mode is now more succinct. [#153361][#153361]
- A database-level changefeed with no tables will
  periodically poll to check for tables added to the database. The new
  option hibernation_polling_frequency sets the frequency at which the
  polling occurs, until a table is found, at which point polling ceases. [#156771][#156771]
- `crdb_internal.datums_to_bytes` is now available in the `information_schema` system catalog as `information_schema.crdb_datums_to_bytes`. [#156963][#156963]
- Queries executed via the vectorized engine
  now display their progress in `phase` column of SHOW QUERIES.
  Previously, this feature was only available in the row-by-row engine. [#158029][#158029]
- Added cluster settings to control the number of concurrent automatic statistics collection jobs:
- `sql.stats.automatic_full_concurrency_limit` controls the maximum number of concurrent full statistics collections. The default is 1.
- `sql.stats.automatic_extremes_concurrency_limit` controls the maximum number of concurrent partial statistics collections using extremes. The default is 128.

Note that at most one statistics collection job can run on a single table at a time. [#158835][#158835]
- Added the `STRICT` option for locality-aware backups. When enabled, backups fail if data from a KV node with one locality tag would be backed up to a bucket with a different locality tag, ensuring data domiciling compliance. [#158999][#158999]
- Fixed a bug where creating a routine could create unnecessary column dependencies when the routine references columns through CHECK constraints (including those for RLS policies and hash-sharded indexes) or partial index predicates. These unnecessary dependencies prevented dropping the column without first dropping the routine. The fix is gated behind the session setting `use_improved_routine_deps_triggers_and_computed_cols`, which is off by default prior to v26.1. [#159126][#159126]
- Changed the default value of the `sql.catalog.allow_leased_descriptors.enabled` cluster setting to `true`. This setting allows introspection tables like `information_schema` and `pg_catalog` to use cached descriptors when building the table results, which improves the performance of introspection queries when there are many tables in the cluster. [#159162][#159162]
- Added support for `SHOW STATEMENT HINTS`, which displays information about the statement hints (if any) associated with the given statement fingerprint string. The fingerprint is normalized in the same way as `EXPLAIN (FINGERPRINT)` before hints are matched. Example usage: `SHOW STATEMENT HINTS FOR ' SELECT * FROM xy WHERE x = 10 '` or `SHOW STATEMENT HINTS FOR $$ SELECT * FROM xy WHERE x = 10 $$ WITH DETAILS`. [#159231][#159231]
- Added a new cluster setting
  `bulkio.import.distributed_merge.mode` to enable distributed merge
  support for IMPORT operations. When enabled (default: false), IMPORT
  jobs will use a two-phase approach where import processors first write
  SST files to local storage, then a coordinator merges and ingests them.
  This can improve performance for large imports by reducing L0 file
  counts and enabling merge-time optimizations. Note: This feature
  requires all nodes to be running version 26.1 or later. [#159330][#159330]
- `INSPECT` is now a generally available (GA) feature. The `enable_inspect_command` session variable has been deprecated, and is now effectively always set to `true`. [#159659][#159659]
- Users can now set the `use_backups_with_ids`
  session setting to enable a new `SHOW BACKUPS IN` experience. When
  enabled, `SHOW BACKUPS IN <collection>` displays all backups in the
  collection. Results can be filtered by backup end time using `OLDER THAN
  <timestamp>` or `NEWER THAN <timestamp>` clauses.
  
  Example usage:
  
      SET use_backups_with_ids = true;
      SHOW BACKUPS IN '<collection>' OLDER THAN '2026-01-09 12:13:14' NEWER THAN '2026-01-04 15:16:17'; [#160137][#160137]
- The `information_schema.crdb_datums_to_bytes` built-in function is now documented. [#160486][#160486]
- Calling `information_schema.crdb_rewrite_inline_hints` now requires the REPAIRCLUSTER privilege. [#160716][#160716]
- Renamed the builtin function `crdb_internal.inject_hint` (introduced in v26.1.0-alpha.2) to `information_schema.crdb_rewrite_inline_hints`. [#160716][#160716]
- If the use_backups_with_ids session variable
  is set, the new SHOW BACKUP experience will be enabled. SHOW BACKUP will
  be able to parse the IDs provided by SHOW BACKUPS and will display
  contents for single backups. [#160812][#160812]
- None [#161211][#161211]
- If the `use_backups_with_ids` session
  variable is set, the new `RESTORE` experience will be enabled. `RESTORE`
  will be able to parse the IDs provided by `SHOW BACKUPS` and will
  restore the specified backup without the use of `AS OF SYSTEM TIME`. [#161294][#161294]
- Updated CockroachDB to allow a prefix of index key columns to be used for the shard column in a hash-sharded index. The `shard_columns` storage parameter may be used to override the default, which uses all index key columns in the shard column. [#161422][#161422]
- CockroachDB now shows execution statistics
  (like `execution time`) on EXPLAIN ANALYZE output for `render` nodes
  which often handle builtin functions. [#161509][#161509]
- Added a session setting to enable/disable the
  optimizer rule InlineAnyProjectSet. The session setting is
  optimizer_inline_any_unnest_subquery, and will be on by default in 26.2+. [#161880][#161880]
- Updated `DROP TRIGGER` to accept the `CASCADE` option for PostgreSQL compatibility. Since triggers in CockroachDB cannot have dependents, `CASCADE` behaves the same as `RESTRICT` or omitting the option entirely. [#161915][#161915]
- Added support for `ALTER TABLE ENABLE TRIGGER` and `ALTER TABLE DISABLE TRIGGER` syntax. This allows users to temporarily disable triggers without dropping them, and later re-enable them. The syntax supports disabling/enabling individual triggers by name, or all triggers on a table using the `ALL` or `USER` keywords. [#161924][#161924]
- Added support for the `pg_trigger_depth()` builtin function, which returns the current nesting level of PostgreSQL triggers (0 if not called from inside a trigger). [#162286][#162286]
- `ALTER TABLE ... DROP CONSTRAINT` can now be used to drop `UNIQUE` constraints. The backing `UNIQUE` index will also be dropped, as CockroachDB treats the constraint and index as the same thing. [#162345][#162345]
- `CREATE OR REPLACE TRIGGER` is now supported. If a trigger with the same name already exists on the same table, it is replaced with the new definition. If no trigger with that name exists, a new trigger is created. [#162633][#162633]
- `DROP COLUMN` and `DROP INDEX` with `CASCADE` now properly drop dependent triggers. Previously, these operations would fail with an unimplemented error when a trigger depended on the column or index being dropped. [#163296][#163296]
- Added support for the `dmetaphone()`, `dmetaphone_alt()`, and `daitch_mokotoff()` built-in functions, completing CockroachDB's implementation of the PostgreSQL `fuzzystrmatch` extension. `dmetaphone` and `dmetaphone_alt` return Double Metaphone phonetic codes for a string, and `daitch_mokotoff` returns an array of Daitch-Mokotoff soundex codes. These functions are useful for fuzzy string matching based on phonetic similarity. [#163430][#163430]
- Row count validation after `IMPORT` is now enabled by default in async mode. After an `IMPORT` completes, a background `INSPECT` job validates that the imported row count matches expectations. The `IMPORT` result now includes an `inspect_job_id` column so the `INSPECT` job can be viewed separately. The `bulkio.import.row_count_validation.mode` cluster setting controls this behavior, with valid values of `off`, `async` (default), and `sync`. [#163543][#163543]
- Added the MAINTAIN privilege, which can be
  granted on tables and materialized views. Users with the MAINTAIN
  privilege on a materialized view can execute REFRESH MATERIALIZED VIEW
  without being the owner. Users with the MAINTAIN privilege on a table
  can execute ANALYZE without needing SELECT. This aligns with PostgreSQL
  17 behavior. [#164236][#164236]

<h3 id="v26-2-0-alpha-1-operational-changes">Operational changes</h3>

- A new cluster setting `kvadmission.store.snapshot_ingest_bandwidth_control.min_rate.enabled` is introduced. When this setting is enabled and disk bandwidth-based admission control is active, snapshot ingestion will be admitted at a minimum rate. This prevents snapshot ingestion from being starved by other elastic work. [#159436][#159436]
- The `kv.range_split.load_sample_reset_duration` cluster setting now defaults to `30m`. This should improve load-based splitting in rare edge cases. [#159499][#159499]
- Added metrics to track protected
  timestamp storage operations for better observability of PTS churn
  and errors.
  
  Informs #104159
  Epic: None [#160129][#160129]
- Changed goroutine profile dumps from human-readable `.txt.gz` files to binary proto `.pb.gz` files. This improves the performance of the goroutine dumper by eliminating brief in-process pauses that occurred when collecting goroutine stacks. [#160798][#160798]
- Added a new structured event of type `rewrite_inline_hints` that is emitted when an inline-hints rewrite rule is added using `information_schema.crdb_rewrite_inline_hints`. This event is written to both the event log and the OPS channel. [#160901][#160901]
- Added a new metric `sql.query.with_statement_hints.count` that is incremented whenever a statement is executed with one or more external statement hints applied. An example of an external statement hint is an inline-hints rewrite rule added by calling `information_schema.crdb_rewrite_inline_hints`. [#161043][#161043]
- The new `cockroach gen dashboard` command generates standardized monitoring dashboards from an embedded configuration file. It outputs a dashboard JSON file for either Datadog (`--tool=datadog`) or Grafana (`--tool=grafana`), with Grafana dashboards using Prometheus queries. The generated dashboards include metrics across Overview, Hardware, Runtime, Networking, SQL, and Storage categories. Use `--output` to set the output file path and `--rollup-interval` to control metric aggregation. [#161050][#161050]
- this patch enables hash sharded indexes and
  secondary indexes with virtually computed columns in LDR. [#161062][#161062]
- TTL jobs are now owned by the schedule owner instead of the `node` user. This allows users with `CONTROLJOB` privilege to cancel TTL jobs, provided the schedule owner is not an admin (`CONTROLJOB` does not grant control over admin-owned jobs). [#161226][#161226]
- Backup schedules that utilize the `revision_history` option now apply that option only to incremental backups triggered by that schedule, rather than duplicating the revision history in the full backups as well. [#162105][#162105]
- ranges are now more accurately
  and likely to be reported as lagging. [#163427][#163427]
- The `build.timestamp` Prometheus metric now carries `major` and `minor` labels identifying the release series of the running CockroachDB binary (e.g. major=26, minor=1 for any v26.1.x build). [#163834][#163834]
- The `bulkio.import.elastic_control.enabled` cluster setting is now enabled by default, allowing import operations to integrate with elastic CPU control and automatically throttle based on available resources. [#163867][#163867]
- The `bulkio.ingest.sst_batcher_elastic_control.enabled` cluster setting is now enabled by default, allowing SST batcher operations to integrate with elastic CPU control and automatically throttle based on available resources. [#163868][#163868]
- Added the `server.sql_tcp_user.timeout`
  cluster setting, which specifies the maximum amount of time transmitted
  data can remain unacknowledged before the underlying TCP connection is
  forcefully closed. This setting is enabled by default with a value of 30
  seconds and is supported on Linux and macOS (Darwin). [#164037][#164037]

<h3 id="v26-2-0-alpha-1-command-line-changes">Command-line changes</h3>

- The `cockroach debug tsdump` command now defaults to `--format=raw` instead of `--format=text`. The `raw` (gob) format is optimized for Datadog ingestion. A new `--output` flag lets you write output directly to a file, avoiding potential file corruption that can occur with shell redirection. If `--output` is not specified, output is written to `stdout`. [#160538][#160538]
- The `cockroach debug tsdump` command now
  supports ZSTD encoding via `--format=raw --encoding=zstd`. This generates
  compressed tsdump files that are ~85% smaller than raw format. The
  `tsdump upload` command automatically detects and decompresses ZSTD
  files, allowing direct upload without manual decompression. [#161998][#161998]
- The `cockroach debug zip` command's
  `--include-files` and `--exclude-files` flags now support full zip path
  patterns. Patterns containing '/' are matched against the full path
  within the zip archive (e.g. `--include-files='debug/nodes/1/*.json'`).
  Patterns without '/' continue to match the base file name as before. [#163266][#163266]
- Added a `--list-dbs` flag to `workload init
  workload_generator` that lists all user databases found in debug logs
  without initializing tables. This helps users discover which databases
  are available in the debug zip before running the full init command.
  
  Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com> [#163930][#163930]

<h3 id="v26-2-0-alpha-1-db-console-changes">DB Console changes</h3>

- The statement details page URL format has changed from `/statement/{implicitTxn}/{statementId}` to `/statement/{statementId}`. As a result, bookmarks using the old URL structure will no longer work. [#159558][#159558]
- The **SQL Activity** > **Sessions** page now defaults the **Session Status** filter to **Active, Idle** to exclude closed sessions. [#160576][#160576]
- Changed the unit of measurement for admission control duration metrics from microseconds to nanoseconds. The following metrics are affected: `admission.granter.slots_exhausted_duration.kv`, `admission.granter.cpu_load_short_period_duration.kv`, `admission.granter.cpu_load_long_period_duration.kv`, `admission.granter.io_tokens_exhausted_duration.kv`, `admission.granter.elastic_io_tokens_exhausted_duration.kv`, and `admission.elastic_cpu.nanos_exhausted_duration`. Note that dashboards displaying these metrics will show a discontinuity at upgrade time, with pre-upgrade values appearing much lower due to the unit change. [#160956][#160956]
- A new time-series bar graph called **Plan Distribution Over Time** has been added to the **Statement Fingerprint** page, on the **Explain Plans** tab. It shows which execution plans were used in each time interval, helping detect shifts in query plan distributions. [#161011][#161011]

<h3 id="v26-2-0-alpha-1-bug-fixes">Bug fixes</h3>

- Fixed a bug that allowed a column to be dropped from a table even if it was referenced in the `RETURNING` clause of an `UPDATE` or `DELETE` statement in a routine. In releases prior to v25.3, the fix must be enabled by setting the session variable `use_improved_routine_dependency_tracking` to `on`. [#146250][#146250]
- CockroachDB could previously encounter internal
  errors like "column statistics cannot be determined for empty column
  set" and "invalid union" in some edge cases with UNION, EXCEPT, and
  INTERCEPT, and this has now been fixed.
  
  ðŸ¤– Generated with [Claude Code](https://claude.ai/code)
  
  Co-Authored-By: Claude <noreply@anthropic.com> [#150706][#150706]
- Fixed a bug that could cause a scan over a secondary
  index to read significantly more KVs than necessary in order to satisfy a
  limit when the scanned index has more than one column family. [#156672][#156672]
- Fixed an issue where long-running transactions with many statements could cause unbounded memory growth in the SQL statistics subsystem. When a transaction includes a large number of statements, the SQL statistics ingester now automatically flushes buffered statistics before the transaction commits. As a side effect, the flushed statement statistics might not have an associated transaction fingerprint ID because the transaction has not yet completed. In such cases, the transaction fingerprint ID cannot be backfilled after the fact. [#158527][#158527]
- Fixed a bug that caused newly-created routines to incorrectly prevent dropping columns that were not directly referenced, most notably columns referenced by computed column expressions. The fix is gated behind the session setting `use_improved_routine_deps_triggers_and_computed_cols`, which is off by default prior to v26.1. [#158935][#158935]
- Fixed a bug that allowed columns to be dropped despite being referenced by a routine. This could occur when a column was only referenced as a target column in the SET clause of an UPDATE statement within the routine. This fix only applies to newly-created routines. In versions prior to v26.1, the fix must be enabled by setting the session variable `prevent_update_set_column_drop`. [#158935][#158935]
- Fixed a bug where schema changes could fail after a `RESTORE` due to missing session data. [#159176][#159176]
- The `ascii` built-in function now returns `0`
  when the input is the empty string instead of an error. [#159178][#159178]
- Fixed a bug where comments associated with constraints were left behind after the column and constraint were dropped. [#159180][#159180]
- A bug has been fixed which could cause prepared
  statements to fail with the error message "non-const expression" when
  they contained filters with stable functions. This bug has been present
  since 25.4.0. [#159201][#159201]
- Fixed a bug in the TPC-C workload where long-duration runs (>= 4 days or indefinite) would experience periodic performance degradation every 24 hours due to excessive concurrent `UPDATE` statements resetting warehouse and district year-to-date values. [#159286][#159286]
- Fixed a race condition where queries run after revoking `BYPASSRLS` could return wrong results because cached plans failed to notice the change immediately. [#159354][#159354]
- Fixed a bug where `TRUNCATE` did not behave correctly with respect to the `schema_locked` storage parameter, and was not being blocked when Logical Data Replication (LDR) was in use. This behavior was incorrect and has been fixed. [#159378][#159378]
- Fixed a race condition that could occur during context cancellation of an incoming snapshot. [#159403][#159403]
- Fixed a bug that could cause a panic during changefeed startup if an error occurred while initializing the metrics controller. [#159431][#159431]
- Fixed a memory accounting issue that could occur when a lease expired due to a SQL liveness session-based timeout. [#159527][#159527]
- Fixed a bug that caused `SHOW CREATE FUNCTION` to error when the function body contained casts from columns to user-defined types. [#159642][#159642]
- Fixed a bug where a query predicate could be ignored when all of the following conditions were met: the query used a lookup join to an index, the predicate constrained a column to multiple values (e.g., `column IN (1, 2)`), and the constrained column followed one or more columns with optional multi-value constraints in the index. This bug was introduced in v24.3.0. [#159722][#159722]
- Fixed a bug where rolling back a transaction that had just rolled back a savepoint would block other transactions accessing the same rows for five seconds. [#160346][#160346]
- Fixed a deadlock that could occur when a statistics creation task panicked. [#160348][#160348]
- Fixed a bug where CockroachDB could crash when handling decimals with negative scales via the extended PGWire protocol. An error is now returned instead, matching PostgreSQL behavior. [#160499][#160499]
- Fixed a bug where the `pprof` UI endpoints for allocs, heap, block, and mutex profiles ignored the seconds parameter and returned immediate snapshots instead of delta profiles. [#160608][#160608]
- v26.1.0-beta.1 and v26.1.0-beta.2 versions of
  CockroachDB could encounter a rare process crash when running TTL jobs,
  and this has now been fixed. [#160674][#160674]
- Fixed a bug where schema changes adding a `NOT NULL` constraint could enter an infinite retry loop if a row violated the constraint and contained certain content (e.g., `"EOF"`). Such errors are now correctly classified and don't cause retries. [#160780][#160780]
- An error will now be reported when the database provided as the argument to a `SHOW REGIONS` or `SHOW SUPER REGIONS` statement does not exist. This bug had been present since version v21.1. [#161014][#161014]
- Fixed a bug where `CREATE INDEX` on a table with `PARTITION ALL BY` would fail if the partition columns were explicitly included in the primary key definition. [#161083][#161083]
- Fixed a bug in which inline-hints rewrite rules created with `information_schema.crdb_rewrite_inline_hints` were not correctly applied to statements run with `EXPLAIN ANALYZE`. This bug was introduced in v26.1.0-alpha.2. [#161273][#161273]
- Fixed a bug where AVRO file imports of data with
  JSON or binary records could hang indefinitely when encountering
  stream errors from cloud storage (such as HTTP/2 CANCEL errors).
  Import jobs will now properly fail with an error instead of hanging. [#161290][#161290]
- Fixed a bug where IMPORT with AVRO data using OCF format could silently lose data if the underlying storage (e.g., S3) returned an error during read. Such errors are now properly reported. Other formats (specified via `data_as_binary_records` and `data_as_json_records` options) are unaffected. The bug has been present since about v20.1. [#161318][#161318]
- Fix a bug which prevented successfully injecting
  hints using `information_schema.crdb_rewrite_inline_hints` for INSERT,
  UPSERT, UPDATE, and DELETE statements. This bug has existed since hint
  injection was introduced in v26.1.0-alpha.2.
  
  Co-Authored-By: Claude <noreply@anthropic.com> [#161773][#161773]
- Fixed prepared statements failing with "version
  mismatch" errors when user-defined types are modified between preparation
  and execution. Prepared statements now automatically detect UDT changes
  and re-parse to use current type definitions. [#161827][#161827]
- Previously, CockroachDB could hit an internal
  error when evaluating builtin functions with `'{}'` as an argument
  (without explicit type casts) (e.g. on a query like
  "SELECT cardinality('{}');"). This is now fixed and a regular error is
  returned instead (matching PG). [#161835][#161835]
- Fixed a bug where the index definition shown in `pg_indexes` for hash sharded indexes with `STORING` columns was not valid SQL. The `STORING` clause now appears in the correct position. [#161882][#161882]
- Fixed a bug where `DROP TABLE ... CASCADE` would incorrectly drop tables that had triggers or row-level security (RLS) policies referencing the dropped table. Now only the triggers/policies are dropped, and the tables owning them remain intact. [#161914][#161914]
- Reduced contention when dropping descriptors or running concurrent imports. [#161941][#161941]
- Previously, if buffered writes were enabled
  (which is a public preview feature, off by default), multi-stmt explicit
  txns that use SAVEPOINTs to recover from certain errors (like duplicate
  key value violations) could lose the writes that were performed _before_
  the savepoint was created in rare cases. The bug has been present since
  the buffered writes feature was added in 25.2 and is now fixed. [#161972][#161972]
- Fixed a bug introduced in v26.1.0-beta.1 in which row-level TTL jobs could encounter GC threshold errors if each node had a large number of spans to process. [#161979][#161979]
- Fixed an error that occurred when using generic
  plan that generates a lookup join on indexes containing identity
  computed columns. [#162036][#162036]
- Fixes a bug in kafka v1 where a changefeed
  could potentially hang if the changefeed was shutting down. [#162058][#162058]
- Fixed an internal error "could not find format
  code for column N" that occurred when executing EXPLAIN ANALYZE EXECUTE
  statements via JDBC or other clients using the PostgreSQL binary
  protocol.
  
  Epic: None
  
  Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com> [#162115][#162115]
- have statement bundles contains the CREATE TYPE
  for User Defined Types (udt) where columns are of udt array type. [#162357][#162357]
- Fix a bug in which PL/pgSQL UDFs with many IF
  statements would cause a timeout and/or OOM when executed from a
  prepared statement. This bug was introduced in v23.2.22, v24.1.15,
  v24.3.9, v25.1.2, v25.2.0. [#162512][#162512]
- Fixed a bug where an error would occur when defining a foreign key on a hash-sharded primary key without explicitly providing the primary key columns. [#162608][#162608]
- Fixes a bug where generating a debug zip causes
  a node to OOM. This OOM happens when a log file contains a malformed
  log and is using json (or json-compact) formatting. [#163224][#163224]
- Fixed an optimizer limitation that prevented
  index usage on computed columns when querying through views or
  subqueries containing JSON fetch expressions (such as ->, ->>, #>, #>>).
  Queries that project JSON expressions matching indexed computed column
  definitions now correctly use indexes instead of performing full table
  scans, significantly improving performance for JSON workloads.
  
  Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com> [#163395][#163395]
- A bug has been fixed that could cause incorrect
  results for any of the following types of statements:
    1. Prepared statements with `LIMIT` expressions where the limit is a
       placeholder and the given placeholder value is negative. This could
       result in a successful query when the correct result is an error.
    2. Prepared statements with `OFFSET` expressions where the limit is
       a placeholder. In some cases this could produce incorrect results.
    3. Statements within a UDF or stored procedure similar to (1) and (2)
       where the limit/offset is a reference to an argument of the UDF/SP. [#163500][#163500]
- Dropping a region from the system database no longer leaves `REGIONAL BY TABLE` system tables referencing the removed region, preventing descriptor validation errors. [#163503][#163503]
- Fixed an issue where changefeeds with
  execution_locality filters could fail in multi-tenant clusters with
  "node descriptor not found" errors.
  
  Epic: none
  Issue: #163752 [#163507][#163507]
- Fixed a bug where `EXPLAIN ANALYZE (DEBUG)` statement bundles did not include triggers, their functions, or tables modified by those triggers. The bundle's `schema.sql` file now contains the `CREATE TRIGGER`, `CREATE FUNCTION`, and `CREATE TABLE` statements needed to fully reproduce the query environment when triggers are involved. [#163584][#163584]
- Fixed a rare data race during parallel constraint
  checks where a fresh descriptor collection could resolve a stale enum
  type version. This data race should only affect 26.1.0. [#163883][#163883]
- Fixed a bug where running **changefeeds** with `envelope=enriched` and `enriched_properties` containing `source` would cause failures during a **cluster upgrade**. [#163885][#163885]
- The fix for "node descriptor
  not found" errors for changefeeds with execution_locality
  filters in serverless clusters is now controlled by
  cluster setting:
  sql.instance_info.use_instance_resolver.enabled
  (default: true).
  
  Epic: none
  Informs: #163752 [#163947][#163947]
- Fixed a bug where dropped columns appeared
  in pg_catalog.pg_attribute with the atttypid column equal to 2283
  (anyelement). Now this column will be 0 for dropped columns. This
  matches PostgreSQL behavior, where atttypid=0 is used for
  dropped columns.
  
  Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com> [#163950][#163950]
- Prevented a race condition/conflict between
  concurrent ALTER FUNCTION ... SET SCHEMA and DROP SCHEMA operations. [#164043][#164043]

<h3 id="v26-2-0-alpha-1-performance-improvements">Performance improvements</h3>

- Database- and table-level backups no longer fetch all object descriptors from disk in order to resolve the backup targets. Now only the objects that are referenced by the targeted objects will be fetched. This improves performance when there are many tables in the cluster. [#157790][#157790]
- Various background tasks and jobs now more actively yield to foreground work when that work is waiting to run. [#159205][#159205]
- Improved changefeed performance
    when filtering unwatched column families and offline tables by replacing
    expensive error chain traversal with direct status enum comparisons.
  
    Epic: None [#159745][#159745]
- Added a new session variable, `distsql_prevent_partitioning_soft_limited_scans`, which, when true, prevents scans with soft limits from being planned as multiple TableReaders by the physical planner. This should decrease the initial setup costs of some fully-distributed query plans. [#160051][#160051]
- The session variable `distsql_prevent_partitioning_soft_limited_scans` is now enabled by default. This prevents scans with soft limits from being planned as multiple TableReaders, which decreases the initial setup costs of some fully-distributed query plans. [#160051][#160051]
- Fixed a performance regression in `pg_catalog.pg_roles` and `pg_catalog.pg_authid` by avoiding privilege lookups for each row in the table. [#160121][#160121]
- Queries that have comparison
  expressions with the `levenshtein` built-in are now up to 30% faster. [#160394][#160394]
- The optimizer now better
  optimizes query plans of statements within UDFs and stored procedures
  that have IN subqueries. [#160503][#160503]
- Significantly reduced WAL write
  latency when using encryption at rest by properly recycling WAL files
  instead of deleting and recreating them.
  
  Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com> [#160784][#160784]
- Optimized the logic that applies zone config constraints so it no longer fetches all descriptors in the cluster during background constraint reconciliation. [#160966][#160966]
- The optimizer can now better handle
  filters that redundantly `unnest()` an array placeholder argument within an
  `IN` or `ANY` filter. Previously, this pattern could prevent the filters from
  being used to constrain a table scan. Example:
  ```SELECT k FROM a WHERE k = ANY(SELECT * FROM unnest($1:::INT[]))``` [#161816][#161816]
- improved the performance on
  changefeed checkpoint when changefeeds are lagging.
  Informs: #158913 [#162546][#162546]

<h3 id="v26-2-0-alpha-1-build-changes">Build changes</h3>

- Replaces bors with Trunk merge queue for better performance and reliability. Configuration-only change with no runtime impact - maintains same safety checks while improving CI workflow. [#161230][#161230]

<h3 id="v26-2-0-alpha-1-miscellaneous">Miscellaneous</h3>

- external connections can now be used with online
  restore [#159090][#159090]
- Fixed a bug where import rollback could incorrectly revert data in a table that was already online. This could only occur if an import job was cancelled or failed after the import had already succeeded and the table was made available for use. [#159627][#159627]
- Invalid avro_schema_prefix is now caught during statement
  time. The prefix must start with [A-Za-z_] and subsequently contain only
  [A-Za-z0-9_], as specified in the avro specification
  https://avro.apache.org/docs/1.8.1/spec.html
  
  Part of: https://github.com/cockroachlabs/support/issues/3513 [#159869][#159869]
- Added `REVISION START TIME` option to new `SHOW BACKUPS`
  UX. Use the option to view revision start times of revision history
  backups. [#161328][#161328]
- `SHOW BACKUP` and `RESTORE` now allow backup IDs even if
  the `use_backups_with_ids` session variable is not set. Setting the
  variable only configures whether `LATEST` is resolved using the new or
  legacy path. [#162329][#162329]
- Job running statuses are now cleared after completing
  successfully. [#163765][#163765]


[#160129]: https://github.com/cockroachdb/cockroach/pull/160129
[#159431]: https://github.com/cockroachdb/cockroach/pull/159431
[#162058]: https://github.com/cockroachdb/cockroach/pull/162058
[#163765]: https://github.com/cockroachdb/cockroach/pull/163765
[#160812]: https://github.com/cockroachdb/cockroach/pull/160812
[#158527]: https://github.com/cockroachdb/cockroach/pull/158527
[#163543]: https://github.com/cockroachdb/cockroach/pull/163543
[#161941]: https://github.com/cockroachdb/cockroach/pull/161941
[#162115]: https://github.com/cockroachdb/cockroach/pull/162115
[#163395]: https://github.com/cockroachdb/cockroach/pull/163395
[#160503]: https://github.com/cockroachdb/cockroach/pull/160503
[#159627]: https://github.com/cockroachdb/cockroach/pull/159627
[#161806]: https://github.com/cockroachdb/cockroach/pull/161806
[#159176]: https://github.com/cockroachdb/cockroach/pull/159176
[#163224]: https://github.com/cockroachdb/cockroach/pull/163224
[#159745]: https://github.com/cockroachdb/cockroach/pull/159745
[#160966]: https://github.com/cockroachdb/cockroach/pull/160966
[#158935]: https://github.com/cockroachdb/cockroach/pull/158935
[#163427]: https://github.com/cockroachdb/cockroach/pull/163427
[#164236]: https://github.com/cockroachdb/cockroach/pull/164236
[#158835]: https://github.com/cockroachdb/cockroach/pull/158835
[#161290]: https://github.com/cockroachdb/cockroach/pull/161290
[#161914]: https://github.com/cockroachdb/cockroach/pull/161914
[#163199]: https://github.com/cockroachdb/cockroach/pull/163199
[#163834]: https://github.com/cockroachdb/cockroach/pull/163834
[#160348]: https://github.com/cockroachdb/cockroach/pull/160348
[#162512]: https://github.com/cockroachdb/cockroach/pull/162512
[#160051]: https://github.com/cockroachdb/cockroach/pull/160051
[#160716]: https://github.com/cockroachdb/cockroach/pull/160716
[#161882]: https://github.com/cockroachdb/cockroach/pull/161882
[#159090]: https://github.com/cockroachdb/cockroach/pull/159090
[#161924]: https://github.com/cockroachdb/cockroach/pull/161924
[#161050]: https://github.com/cockroachdb/cockroach/pull/161050
[#163266]: https://github.com/cockroachdb/cockroach/pull/163266
[#161083]: https://github.com/cockroachdb/cockroach/pull/161083
[#163503]: https://github.com/cockroachdb/cockroach/pull/163503
[#160784]: https://github.com/cockroachdb/cockroach/pull/160784
[#161880]: https://github.com/cockroachdb/cockroach/pull/161880
[#159162]: https://github.com/cockroachdb/cockroach/pull/159162
[#160137]: https://github.com/cockroachdb/cockroach/pull/160137
[#159436]: https://github.com/cockroachdb/cockroach/pull/159436
[#163868]: https://github.com/cockroachdb/cockroach/pull/163868
[#160121]: https://github.com/cockroachdb/cockroach/pull/160121
[#159231]: https://github.com/cockroachdb/cockroach/pull/159231
[#161226]: https://github.com/cockroachdb/cockroach/pull/161226
[#160576]: https://github.com/cockroachdb/cockroach/pull/160576
[#163883]: https://github.com/cockroachdb/cockroach/pull/163883
[#163885]: https://github.com/cockroachdb/cockroach/pull/163885
[#157790]: https://github.com/cockroachdb/cockroach/pull/157790
[#160486]: https://github.com/cockroachdb/cockroach/pull/160486
[#162286]: https://github.com/cockroachdb/cockroach/pull/162286
[#159330]: https://github.com/cockroachdb/cockroach/pull/159330
[#162036]: https://github.com/cockroachdb/cockroach/pull/162036
[#159722]: https://github.com/cockroachdb/cockroach/pull/159722
[#146250]: https://github.com/cockroachdb/cockroach/pull/146250
[#162345]: https://github.com/cockroachdb/cockroach/pull/162345
[#150706]: https://github.com/cockroachdb/cockroach/pull/150706
[#163947]: https://github.com/cockroachdb/cockroach/pull/163947
[#161925]: https://github.com/cockroachdb/cockroach/pull/161925
[#159180]: https://github.com/cockroachdb/cockroach/pull/159180
[#160608]: https://github.com/cockroachdb/cockroach/pull/160608
[#163584]: https://github.com/cockroachdb/cockroach/pull/163584
[#163430]: https://github.com/cockroachdb/cockroach/pull/163430
[#161294]: https://github.com/cockroachdb/cockroach/pull/161294
[#161062]: https://github.com/cockroachdb/cockroach/pull/161062
[#160780]: https://github.com/cockroachdb/cockroach/pull/160780
[#162357]: https://github.com/cockroachdb/cockroach/pull/162357
[#161816]: https://github.com/cockroachdb/cockroach/pull/161816
[#159126]: https://github.com/cockroachdb/cockroach/pull/159126
[#160956]: https://github.com/cockroachdb/cockroach/pull/160956
[#159378]: https://github.com/cockroachdb/cockroach/pull/159378
[#161972]: https://github.com/cockroachdb/cockroach/pull/161972
[#163950]: https://github.com/cockroachdb/cockroach/pull/163950
[#164043]: https://github.com/cockroachdb/cockroach/pull/164043
[#160798]: https://github.com/cockroachdb/cockroach/pull/160798
[#156672]: https://github.com/cockroachdb/cockroach/pull/156672
[#162546]: https://github.com/cockroachdb/cockroach/pull/162546
[#153361]: https://github.com/cockroachdb/cockroach/pull/153361
[#159659]: https://github.com/cockroachdb/cockroach/pull/159659
[#161773]: https://github.com/cockroachdb/cockroach/pull/161773
[#161827]: https://github.com/cockroachdb/cockroach/pull/161827
[#158029]: https://github.com/cockroachdb/cockroach/pull/158029
[#162608]: https://github.com/cockroachdb/cockroach/pull/162608
[#161328]: https://github.com/cockroachdb/cockroach/pull/161328
[#159354]: https://github.com/cockroachdb/cockroach/pull/159354
[#161509]: https://github.com/cockroachdb/cockroach/pull/161509
[#164037]: https://github.com/cockroachdb/cockroach/pull/164037
[#160394]: https://github.com/cockroachdb/cockroach/pull/160394
[#162302]: https://github.com/cockroachdb/cockroach/pull/162302
[#161211]: https://github.com/cockroachdb/cockroach/pull/161211
[#159499]: https://github.com/cockroachdb/cockroach/pull/159499
[#161043]: https://github.com/cockroachdb/cockroach/pull/161043
[#161835]: https://github.com/cockroachdb/cockroach/pull/161835
[#159205]: https://github.com/cockroachdb/cockroach/pull/159205
[#156771]: https://github.com/cockroachdb/cockroach/pull/156771
[#156963]: https://github.com/cockroachdb/cockroach/pull/156963
[#162633]: https://github.com/cockroachdb/cockroach/pull/162633
[#162105]: https://github.com/cockroachdb/cockroach/pull/162105
[#160538]: https://github.com/cockroachdb/cockroach/pull/160538
[#159201]: https://github.com/cockroachdb/cockroach/pull/159201
[#159403]: https://github.com/cockroachdb/cockroach/pull/159403
[#160346]: https://github.com/cockroachdb/cockroach/pull/160346
[#161265]: https://github.com/cockroachdb/cockroach/pull/161265
[#159178]: https://github.com/cockroachdb/cockroach/pull/159178
[#159642]: https://github.com/cockroachdb/cockroach/pull/159642
[#163507]: https://github.com/cockroachdb/cockroach/pull/163507
[#161011]: https://github.com/cockroachdb/cockroach/pull/161011
[#161422]: https://github.com/cockroachdb/cockroach/pull/161422
[#161998]: https://github.com/cockroachdb/cockroach/pull/161998
[#164225]: https://github.com/cockroachdb/cockroach/pull/164225
[#163867]: https://github.com/cockroachdb/cockroach/pull/163867
[#163930]: https://github.com/cockroachdb/cockroach/pull/163930
[#159558]: https://github.com/cockroachdb/cockroach/pull/159558
[#160674]: https://github.com/cockroachdb/cockroach/pull/160674
[#163500]: https://github.com/cockroachdb/cockroach/pull/163500
[#158999]: https://github.com/cockroachdb/cockroach/pull/158999
[#160499]: https://github.com/cockroachdb/cockroach/pull/160499
[#161014]: https://github.com/cockroachdb/cockroach/pull/161014
[#161273]: https://github.com/cockroachdb/cockroach/pull/161273
[#163296]: https://github.com/cockroachdb/cockroach/pull/163296
[#162329]: https://github.com/cockroachdb/cockroach/pull/162329
[#159787]: https://github.com/cockroachdb/cockroach/pull/159787
[#160901]: https://github.com/cockroachdb/cockroach/pull/160901
[#161230]: https://github.com/cockroachdb/cockroach/pull/161230
[#159869]: https://github.com/cockroachdb/cockroach/pull/159869
[#159189]: https://github.com/cockroachdb/cockroach/pull/159189
[#161915]: https://github.com/cockroachdb/cockroach/pull/161915
[#159286]: https://github.com/cockroachdb/cockroach/pull/159286
[#159527]: https://github.com/cockroachdb/cockroach/pull/159527
[#161318]: https://github.com/cockroachdb/cockroach/pull/161318
[#161979]: https://github.com/cockroachdb/cockroach/pull/161979
[#160416]: https://github.com/cockroachdb/cockroach/pull/160416
