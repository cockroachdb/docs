## v23.2.0

Release Date: TODO

With the release of CockroachDB v23.2, we've added new capabilities in CockroachDB to help you migrate, build, and operate more efficiently. Check out a [summary of the most significant user-facing changes](#v23-2-0-feature-highlights) and then [upgrade to CockroachDB v23.2](https://www.cockroachlabs.com/docs/v23.2/upgrade-cockroach-version).

{% include releases/release-downloads-docker-image.md release=include.release advisory_key="a103220"%}

<h3 id="v23-2-0-feature-highlights">Feature highlights</h3>

This section summarizes the most significant user-facing changes in v23.2.0. For a complete list of features and changes, including bug fixes and performance improvements, see the [release notes]({% link releases/index.md %}#testing-releases) for previous testing releases. You can also search for [what's new in v23.2 in our docs](https://www.cockroachlabs.com/docs/search?query=new+in+v23.2).

{{site.data.alerts.callout_info}}
The features highlighted below are freely available in CockroachDB {{ site.data.products.core }} and do not require an [enterprise license](https://www.cockroachlabs.com/docs/v23.2/cockroach-demo) to test enterprise features in a local, temporary cluster.
{{site.data.alerts.end}}

- [Enterprise Edition Changes](#v23-2-0-enterprise-edition-changes)
- [SQL](#v23-2-0-sql)
- [Security and compliance](#v23-2-0-security-and-compliance)
- [Recovery and I/O](#v23-2-0-recovery-and-io)
- [Database operations](#v23-2-0-database-operations)
- [Backward-incompatible changes](#v23-2-0-backward-incompatible-changes)
- [Deprecations](#v23-2-0-deprecations)
- [Known limitations](#v23-2-0-known-limitations)
- [Additional resources](#v23-2-0-additional-resources)

<style>
    table td:first-child {
        min-width: 100px !important;
    }
    table td:nth-child(2) {
        min-width: 200px !important;
    }
</style>

<h4 id="v23-2-0-enterprise-edition-changes">Enterprise Edition Changes</h4>

The following features require an [Enterprise license](https://www.cockroachlabs.com/docs/v23.2/enterprise-licensing):

- [Column-level encryption]({% link v23.2/column-level-encryption.md %}) allows you to encrypt one or more of the columns in each row of a database table, and can be useful for compliance scenarios such as adhering to PCI or GDPR.
- [Physical cluster replication (Preview)]({% link v23.2/physical-cluster-replication-overview.md %}) continuously sends all data at the byte level from a _primary cluster_ to an independent _standby cluster_. Existing data and ongoing changes on the active primary cluster, which is serving application data, replicate asynchronously to the passive standby cluster. In a disaster recovery scenario, you can cut over from the unavailable primary cluster to the standby cluster. This will stop the replication stream, reset the standby cluster to a point in time where all ingested data is consistent, and mark the standby as ready to accept application traffic.

<h4 id="v23-2-0-sql">SQL</h4>

TODO

<h4 id="v23-2-0-security-and-compliance">Security and compliance</h4>

TODO

<h4 id="v23-2-0-database-operations">Database Operations</h4>

TODO

<h4 id="v23-2-0-backward-incompatible-changes">Backward-incompatible changes</h4>

Before [upgrading to CockroachDB v23.2]({% link v23.2/upgrade-cockroach-version.md %}), be sure to review the following backward-incompatible changes, as well as key cluster setting changes, and adjust your deployment as necessary.

<!-- alpha.1 TODO: Remove this comment -->
- The pre-v23.1 output produced by `SHOW RANGES`, `crdb_internal.ranges`, and `crdb_internal.ranges_no_leases` was deprecated in v23.1 and is now replaced by default with output that's compatible with coalesced ranges (anges that pack multiple tables/indexes/partitions into individual ranges). See the [v23.1 release notes]({% link releases/v23.1.md %}) for `SHOW RANGES` for more details. [#102961][#102961]
- When a deployment is configured to use a time zone (new feature) for log file output using formats `crdb-v1` or `crdb-v2`, it becomes impossible to process the new output log files using the [`cockroach debug merge-logs` command]({% link v23.2/cockroach-debug-merge-logs.md %}) from a previous version. The newest `cockroach debug merge-logs` code must be used instead. [#104265][#104265]
- When customizing the [SQL shell's interactive prompt]({% link v23.2/cockroach-sql.md %}), the special sequence `%M` now expands to the full host name instead of the combination of host name and port number. To include the port number explicitly, use `%>`. The special sequence `%m` now expands to the host name up to the first period. [#105137][#105137]
- The [`cockroach debug zip`]({% link v23.2/cockroach-debug-zip.md %}) command stores data retrieved from SQL tables in the remote cluster using the TSV format by default. [#107474][#107474]
<!-- alpha.3 TODO: Remove this comment -->
- The direct export of traces to Jaeger and the [cluster setting](../v23.2/cluster-settings.html) `trace.jaeger.agent` have been removed. The direct export functionality had been obsoleted since 2022; it stopped working altogether sometime in 2023 with the following error: `data does not fit within one UDP packet; size 65006, max 65000, spans NN`. Since 2022, Jaeger supports ingestion of traces using OTLP; and CockroachDB has supported emitting traces using OTLP since v22.1. Operators and developers who want to inspect traces are thus invited to use the OTLP protocol instead. The corresponding cluster setting is `trace.opentelemetry.collector`. For a successful deployment, an intermediate OTLP collector/forwarder should be configured.

  You can orchestrate the OpenTeletry collector and Jaeger together using Docker Compose by adapting the following example:

    ~~~ yaml
    otel-collector:
      image: otel/opentelemetry-collector-contrib
      container_name: otel-collector
      volumes:
        - ./otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
      ports:
        - 1888:1888 # pprof extension
        - 8888:8888 # Prometheus metrics exposed by the collector
        - 8889:8889 # Prometheus exporter metrics
        - 13133:13133 # health_check extension
        - 4317:4317 # OTLP gRPC receiver
        - 4318:4318 # OTLP http receiver
        - 55679:55679 # zpages extension

    jaeger:
      image: jaegertracing/all-in-one
      container_name: jaeger
      ports:
        - "16685:16685"
        - "16686:16686"
        - "14250:14250"
        - "14268:14268"
        - "14269:14269"
        - "6831:6831/udp"
      environment:
        - COLLECTOR_ZIPKIN_HTTP_PORT=9411
        - COLLECTOR_OTLP_ENABLED=true
    ~~~

  To configure the `otel-collector`, you can adapt this example:

    ~~~ yaml
    receivers:
      otlp: # the OTLP receiver the app is sending traces to
        protocols:
          grpc:
          http:

    processors:
      batch:

    exporters:
      otlp/jaeger: # Jaeger supports OTLP directly
        endpoint: http://jaeger:4317
        tls:
          insecure: true

    service:
      pipelines:
        traces/dev:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp/jaeger]
    ~~~

  To use this configuration, unset Jaeger via `SET CLUSTER SETTING trace.jaeger.agent=''`, and then set the OTLP collector using `SET CLUSTER SETTING trace.opentelemetry.collector='localhost:4317'`.
<!-- alpha.1 TODO: Remove this comment -->


<h4 id="v23-2-0-cluster-settings">Key Cluster Setting Changes</h4>

The following changes should be reviewed prior to upgrading. Default cluster settings will be used unless you have manually set a value for a setting. This can be confirmed by checking the `system.settings` table (`select * from system.settings`) to view the non-default settings.

<!-- Rolled up from alpha.1 through beta.3 -->
- The new [cluster setting]({% link v23.2/cluster-settings.md %}) `sql.txn.read_committed_syntax.enabled`, controls whether transactions run under `READ COMMITTED` or `SERIALIZABLE` isolation. It defaults to `false`. When set to `true`, the following statements will configure transactions to run under `READ COMMITTED` isolation:

  - `BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED`
  - `SET TRANSACTION ISOLATION LEVEL READ COMMITTED`
  - `SET default_transaction_isolation = 'read committed'`
  - `SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL READ COMMITTED`

    [#110624][#110624]
- The `sql.txn.read_committed_syntax.enabled` [cluster setting](../v23.2/cluster-settings.html) was renamed to [`sql.txn.read_committed_isolation.enabled`](../v23.2/cluster-settings.html#setting-sql-txn-read-committed-isolation-enabled). [#113833][#113833]
- Users who have the [`CREATEROLE` role option]({% link v23.2/grant.md %}) can now grant and revoke role membership in any non-admin role. This change also removes the [`sql.auth.createrole_allows_grant_role_membership.enabled` cluster setting]({% link v23.2/cluster-settings.md %}), which was added in v23.1. In v23.2, the cluster setting is effectively always true. [#104376][#104376]
- The [cluster setting]({% link v23.2/cluster-settings.md %}) `kv.rangefeed.enabled` no longer controls access to `RANGEFEED SQL` commands. Instead, use `feature.changefeed.enabled`. [#110676][#110676]
- The [cluster settings]({% link v23.2/cluster-settings.md %}) related to [physical cluster replication](../v23.2/physical-cluster-replication-overview.html) have been renamed for consistency. For example, `bulkio.stream_ingestion.minimum_flush_interval` is now named `physical_replication.consumer.minimum_flush_interval`. [#111197][#111197]
- CockroachDB now periodically dumps the state of its internal memory accounting system into the `heap_profiler/` directory when a heap profile is taken. To disable this behavior, set the `diagnostics.memory_monitoring_dumps.enabled` [cluster setting]({% link v23.2/cluster-settings.md %}) to `false`. [#114998][#114998]

<h4 id="v23-2-0-deprecations">Deprecations</h4>

TODO

<h4 id="v23-2-0-known-limitations">Known limitations</h4>

For information about new and unresolved limitations in CockroachDB v23.1, with suggested workarounds where applicable, see [Known Limitations](https://www.cockroachlabs.com/docs/v23.2/known-limitations).

<h4 id="v23-2-0-additional-resources">Additional resources</h4>

Resource             | Topic                                      | Description
---------------------+--------------------------------------------+-------------
Cockroach University | [Introduction to Distributed SQL and CockroachDB](https://university.cockroachlabs.com/courses/course-v1:crl+intro-to-distributed-sql-and-cockroachdb+self-paced/about) | This course introduces the core concepts behind distributed SQL databases and describes how CockroachDB fits into this landscape. You will learn what differentiates CockroachDB from both legacy SQL and NoSQL databases and how CockroachDB ensures consistent transactions without sacrificing scale and resiliency. You'll learn about CockroachDB's seamless horizontal scalability, distributed transactions with strict ACID guarantees, and high availability and resilience.
Cockroach University | [Practical First Steps with CockroachDB](https://university.cockroachlabs.com/courses/course-v1:crl+practical-first-steps-with-crdb+self-paced/about) | This course will give you the tools you need to get started with CockroachDB. During the course, you will learn how to spin up a cluster, use the Admin UI to monitor cluster activity, and use SQL shell to solve a set of hands-on exercises.
Cockroach University | [Building a Highly Resilient Multi-region Database using CockroachDB](https://university.cockroachlabs.com/courses/course-v1:crl+intro-to-resilience-in-multi-region+self-paced/about) | This course is part of a series introducing solutions to running low-latency, highly resilient applications for data-intensive workloads on CockroachDB. In this course we focus on surviving large-scale infrastructure failures like losing an entire cloud region without losing data during recovery. Weâ€™ll show you how to use CockroachDB survival goals in a multi-region cluster to implement a highly resilient database that survives node or network failures across multiple regions with zero data loss.
Cockroach University | [Introduction to Serverless Databases and CockroachDB Serverless](https://university.cockroachlabs.com/courses/course-v1:crl+intro-to-serverless+self-paced/about) | This course introduces the core concepts behind serverless databases and gives you the tools you need to get started with CockroachDB Serverless. You will learn how serverless databases remove the burden of configuring, sizing, provisioning, securing, maintaining and dynamically scaling your database based on load. This means you simply pay for the serverless database resources you use.
Docs                 | [Migration Overview](https://www.cockroachlabs.com/docs/v23.2/migration-overview) | This page summarizes the steps of migrating a database to CockroachDB, which include testing and updating your schema to work with CockroachDB, moving your data into CockroachDB, and testing and updating your application.
Docs                 | [Developer Guide Overview](https://www.cockroachlabs.com/docs/v23.2/developer-guide-overview) | This page provides an overview of resources available to developers building applications on CockroachDB.
Docs                 | [Security Overview](https://www.cockroachlabs.com/docs/v23.2/security-reference/security-overview) | The 23.1 release encapsulates a number of security milestones. See the security overview for a summary.
Docs                 | [Architecture Overview](https://www.cockroachlabs.com/docs/v23.2/architecture/overview) | This page provides a starting point for understanding the architecture and design choices that enable CockroachDB's scalability and consistency capabilities.
Docs                 | [SQL Feature Support](https://www.cockroachlabs.com/docs/v23.2/sql-feature-support) | The page summarizes the standard SQL features CockroachDB supports as well as common extensions to the standard.
Docs                 | [Change Data Capture Overview](https://www.cockroachlabs.com/docs/v23.2/change-data-capture-overview) | This page summarizes CockroachDB's data streaming capabilities. Change data capture (CDC) provides efficient, distributed, row-level changefeeds into a configurable sink for downstream processing such as reporting, caching, or full-text indexing.
Docs                 | [Backup Architecture](https://www.cockroachlabs.com/docs/v23.2/backup-architecture) | This page describes the backup job workflow with a high-level overview, diagrams, and more details on each phase of the job.
