## v26.1.0-beta.3

Release Date: January 14, 2025

{% include releases/new-release-downloads-docker-image.md release=include.release %}

<h3 id="v26-1-0-beta-3-{{-site.data.products.enterprise-}}-edition-changes">{{ site.data.products.enterprise }} edition changes</h3>

- Added a new cluster setting, `security.provisioning.oidc.enabled`, to allow automatic provisioning of users when they log in for the first time via OIDC. When enabled, a new user will be created in CockroachDB upon their first successful OIDC authentication. This feature is disabled by default. [#160016][#160016]

<h3 id="v26-1-0-beta-3-sql-language-changes">SQL language changes</h3>

<a name="v26-1-0-beta-3-leased-descriptors-default"></a>
- Changed the default value of the `sql.catalog.allow_leased_descriptors.enabled` cluster setting to `true`. This setting allows introspection tables like `information_schema` and `pg_catalog` to use cached descriptors when building the table results, which improves the performance of introspection queries when there are many tables in the cluster. [#159566][#159566]
- Added cluster settings to control the number of concurrent automatic statistics collection jobs:
    - `sql.stats.automatic_full_concurrency_limit` controls the maximum number of concurrent full statistics collections. The default is 1.
    - `sql.stats.automatic_extremes_concurrency_limit` controls the maximum number of concurrent partial statistics collections using extremes. The default is 128.

    Note that at most one statistics collection job can run on a single table at a time. [#159870][#159870]

<h3 id="v26-1-0-beta-3-operational-changes">Operational changes</h3>

- The `kv.range_split.load_sample_reset_duration` cluster setting now defaults to `30m`. This should improve load-based splitting in rare edge cases. [#159677][#159677]

<h3 id="v26-1-0-beta-3-bug-fixes">Bug fixes</h3>

- Fixed an issue where long-running transactions with many statements could cause unbounded memory growth in the SQL statistics subsystem. When a transaction includes a large number of statements, the SQL statistics ingester now automatically flushes buffered statistics before the transaction commits. As a side effect, the flushed statement statistics might not have an associated transaction fingerprint ID because the transaction has not yet completed. In such cases, the transaction fingerprint ID cannot be backfilled after the fact. [#159644][#159644]
- Fixed a bug where a query predicate could be ignored when all of the following conditions were met: the query used a lookup join to an index, the predicate constrained a column to multiple values (e.g., `column IN (1, 2)`), and the constrained column followed one or more columns with optional multi-value constraints in the index. This bug was introduced in v24.3.0. [#159778][#159778]
- Fixed a deadlock that could occur when a statistics creation task panicked. [#160422][#160422]
- Fixed a bug where rolling back a transaction that had just rolled back a savepoint would block other transactions accessing the same rows for five seconds. [#160477][#160477]
- Fixed a bug where CockroachDB could crash when handling decimals with negative scales via the extended PGWire protocol. An error is now returned instead, matching PostgreSQL behavior. [#160561][#160561]
- v26.1.0-beta.1 and v26.1.0-beta.2 versions of
  CockroachDB could encounter a rare process crash when running TTL jobs,
  and this has now been fixed. [#160689][#160689]

<h3 id="v26-1-0-beta-3-performance-improvements">Performance improvements</h3>

- Fixed a performance regression in `pg_catalog.pg_roles` and `pg_catalog.pg_authid` by avoiding privilege lookups for each row in the table. [#160228][#160228]
- Added a new session variable, `distsql_prevent_partitioning_soft_limited_scans`, which defaults to true. When enabled, this prevents scans with soft limits from being planned as multiple TableReaders, which decreases the initial setup costs of some fully-distributed query plans. [#160600][#160600]

<h3 id="v26-1-0-beta-3-miscellaneous">Miscellaneous</h3>

- Fixed a bug where import rollback could incorrectly revert data in a table that was already online. This could only occur if an import job was cancelled or failed after the import had already succeeded and the table was made available for use. [#159904][#159904]


[#160600]: https://github.com/cockroachdb/cockroach/pull/160600
[#159904]: https://github.com/cockroachdb/cockroach/pull/159904
[#160016]: https://github.com/cockroachdb/cockroach/pull/160016
[#159870]: https://github.com/cockroachdb/cockroach/pull/159870
[#159778]: https://github.com/cockroachdb/cockroach/pull/159778
[#160422]: https://github.com/cockroachdb/cockroach/pull/160422
[#160561]: https://github.com/cockroachdb/cockroach/pull/160561
[#160228]: https://github.com/cockroachdb/cockroach/pull/160228
[#159566]: https://github.com/cockroachdb/cockroach/pull/159566
[#159677]: https://github.com/cockroachdb/cockroach/pull/159677
[#159644]: https://github.com/cockroachdb/cockroach/pull/159644
[#160477]: https://github.com/cockroachdb/cockroach/pull/160477
[#160689]: https://github.com/cockroachdb/cockroach/pull/160689
