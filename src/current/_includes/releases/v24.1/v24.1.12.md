## v24.1.12

Release Date: February 6, 2025

{% include releases/new-release-downloads-docker-image.md release=include.release %}

<h3 id="v24-1-12-general-changes">General changes</h3>

- The protected timestamp records of running changefeeds are now updated when the set of targets changes, such as when system tables are added to the protected tables list. [#138668][#138668]

<h3 id="v24-1-12-sql-language-changes">SQL language changes</h3>

- Since v23.2 table statistics histograms have been collected for non-indexed JSON columns. Histograms are no longer collected for these columns if the `sql.stats.non_indexed_json_histograms.enabled` cluster setting is set to `false`. This reduces memory usage during table statistics collection, for both automatic and manual collection via `ANALYZE` and `CREATE STATISTICS`. [#140268][#140268]
- Added support for a new index hint, `AVOID_FULL_SCAN`, which will prevent the optimizer from planning a full scan for the specified table if any other plan is possible. The hint can be used in the same way as other existing index hints. For example, `SELECT * FROM table_name@{AVOID_FULL_SCAN};`. This hint is similar to `NO_FULL_SCAN`, but will not error if a full scan cannot be avoided. Note that normally a full scan of a partial index would not be considered a "full scan" for the purposes of the `NO_FULL_SCAN` and `AVOID_FULL_SCAN` hints, but if the user has explicitly forced the partial index via `FORCE_INDEX=index_name`, CockroachDB does consider it a full scan. [#140272][#140272]
- Added the `optimizer_prefer_bounded_cardinality` session setting, which instructs the optimizer to prefer query plans where every expression has a guaranteed upper-bound on the number of rows it will process. This may help the optimizer produce better query plans in some cases. This setting is disabled by default. [#140272][#140272]
- Added the `optimizer_min_row_count` session setting, which sets a lower bound on row count estimates for relational expressions during query planning. A value of zero, which is the default, indicates no lower bound. Note that if this is set to a value greater than zero, a row count of zero can still be estimated for expressions with a cardinality of zero, e.g., for a contradictory filter. Setting this to a value higher than `0`, such as `1`, may yield better query plans in some cases, such as when statistics are frequently stale and inaccurate. [#140272][#140272]

<h3 id="v24-1-12-operational-changes">Operational changes</h3>

- Added new metrics that expose the TTL for various certificates. [#138659][#138659]
- Introduced the metric `sql.schema_changer.object_count` that keeps track of the count of objects in the cluster. [#138839][#138839]

<h3 id="v24-1-12-bug-fixes">Bug fixes</h3>

- `ALTER BACKUP SCHEDULE` no longer fails on schedules with a collection URI that contains a space. [#138080][#138080]
- Previously, `SHOW CREATE TABLE` was showing incorrect data with regards to inverted indexes. It now shows the correct data that can be repeatedly entered back into CockroachDB to recreate the same table. [#138168][#138168]
- Fixed a bug where querying the `pg_catalog.pg_constraint` table while the schema changer was dropping a constraint could result in a query error. [#138285][#138285]
- Fixed a timing issue between `ALTER VIEW .. RENAME` and `DROP VIEW` that caused repeated failures in the `DROP VIEW` job. [#137887][#137887]
- Queries that perform a cast from the string representation of an array containing `GEOMETRY` or `GEOGRAPHY` types to a SQL array type will now succeed. [#138693][#138693]
- `security.certificate.*` metrics will now be updated if a node loads new certificates while running. [#138659][#138659]
- When the session variable `allow_role_memberships_to_change_during_transaction` is set, it is now possible to create and drop users quickly even when there are contending transactions on the `system.users` and `system.role_options` system tables. [#139027][#139027]
- Fixed a bug where the error `batch timestamp ... must be after replica GC threshold` could occur during a schema change backfill operation, and cause the schema change job to retry infinitely. Now this error is treated as permanent, and will cause the job to enter the `failed` state. [#139248][#139248]
- CockroachDB could previously hit a bounded memory leak when collecting table statistics on a table that had both very wide (10KiB or more) and relatively small (under 400B) `BYTES`-like values within the same row. This has been present since before v19.2. Additionally, in v24.1.0, a bug was introduced that made this leak also apply to `STRING`-like values. [#139174][#139174]

[#137887]: https://github.com/cockroachdb/cockroach/pull/137887
[#138080]: https://github.com/cockroachdb/cockroach/pull/138080
[#138168]: https://github.com/cockroachdb/cockroach/pull/138168
[#138285]: https://github.com/cockroachdb/cockroach/pull/138285
[#138659]: https://github.com/cockroachdb/cockroach/pull/138659
[#138668]: https://github.com/cockroachdb/cockroach/pull/138668
[#138693]: https://github.com/cockroachdb/cockroach/pull/138693
[#138839]: https://github.com/cockroachdb/cockroach/pull/138839
[#139027]: https://github.com/cockroachdb/cockroach/pull/139027
[#139174]: https://github.com/cockroachdb/cockroach/pull/139174
[#139248]: https://github.com/cockroachdb/cockroach/pull/139248
[#140268]: https://github.com/cockroachdb/cockroach/pull/140268
[#140272]: https://github.com/cockroachdb/cockroach/pull/140272
