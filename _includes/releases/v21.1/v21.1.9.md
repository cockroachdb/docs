## v21.1.9

Release Date: September 20, 2021

{% include releases/release-downloads-docker-image.md release=include.release %}

<h3 id="v21-1-9-sql-language-changes">SQL language changes</h3>

- Added the [`bulkio.backup.proxy_file_writes.enabled`](../v21.1/cluster-settings.html) cluster setting to opt-in to writing backup files outside the KV storage layer. [#69250][#69250]
- You can now alter the owner of the `crdb_internal_region` type which is created by initiating a [multi-region database](../v21.1/multiregion-overview.html). [#69759][#69759]

<h3 id="v21-1-9-operational-changes">Operational changes</h3>

- A new cluster setting, [`sql.mutations.max_row_size.log`](../v21.1/cluster-settings.html), was added, which controls large row logging. Whenever a row larger than this size is written (or a single column family if multiple column families are in use) a `LargeRow` event is logged to the `SQL_PERF` channel (or a `LargeRowInternal` event is logged to `SQL_INTERNAL_PERF` if the row was added by an internal query). This could occur for `INSERT`, `UPSERT`, `UPDATE`, `CREATE TABLE AS`, `CREATE INDEX`, `ALTER TABLE`, `ALTER INDEX`, `IMPORT`, or `RESTORE` statements. `SELECT`, `DELETE`, `TRUNCATE`, and `DROP` are not affected by this setting. This setting is disabled by default. [#69946][#69946]
- A new cluster setting, [`sql.mutations.max_row_size.err`](../v21.1/cluster-settings.html), was added, which limits the size of rows written to the database (or individual column families, if multiple column families are in use). Statements trying to write a row larger than this will fail with a code 54000 (`program_limit_exceeded`) error. Internal queries writing a row larger than this will not fail, but will log a `LargeRowInternal` event to the `SQL_INTERNAL_PERF` channel. This limit is enforced for `INSERT`, `UPSERT`, and `UPDATE` statements. `CREATE TABLE AS`, `CREATE INDEX`, `ALTER TABLE`, `ALTER INDEX`, `IMPORT`, and `RESTORE` will not fail with an error, but will log `LargeRowInternal` events to the `SQL_INTERNAL_PERF` channel. `SELECT`, `DELETE`, `TRUNCATE`, and `DROP` are not affected by this limit. Note that existing rows violating the limit *cannot* be updated, unless the update shrinks the size of the row below the limit, but *can* be selected, deleted, altered, backed-up, and restored. For this reason we recommend using the accompanying setting `sql.mutations.max_row_size.log` in conjunction with `SELECT pg_column_size()` queries to detect and fix any existing large rows before lowering `sql.mutations.max_row_size.err`. This setting is disabled by default. [#69946][#69946]
- New variables `sql.mutations.max_row_size.{log|err}` were renamed to `sql.guardrails.max_row_size_{log|err}` for consistency with other variables and metrics. [#69946][#69946]
- Added four new metrics: `sql.guardrails.max_row_size_log.count`, `sql.guardrails.max_row_size_log.count.internal`, `sql.guardrails.max_row_size_err.count`, and `sql.guardrails.max_row_size_err.count.internal`. These metrics are incremented whenever a large row violates the corresponding `sql.guardrails.max_row_size_{log|err}` limit. [#69946][#69946]

<h3 id="v21-1-9-db-console-changes">DB Console changes</h3>

- A CES survey link component was added to support being able to get client feedback. [#68517][#68517]

<h3 id="v21-1-9-bug-fixes">Bug fixes</h3>

- Fixed a bug where running [`IMPORT PGDUMP`](../v21.1/migrate-from-postgres.html) with a UDT would result in a null pointer exception. This change makes it fail gracefully. [#69249][#69249]
- Fixed a bug where the `schedules.backup.succeeded` and `schedules.backup.failed` metrics would sometimes not be updated. [#69256][#69256]
- The correct format code will now be returned when using [`COPY FROM .. BINARY`](../v21.1/copy-from.html). [#69278][#69278]
- Fixed a bug where [`COPY FROM ... BINARY`](../v21.1/copy-from.html) would return an error if the input data was split across different messages. [#69278][#69278]
- Fixed a bug where [`COPY FROM ... CSV`](../v21.1/copy-from.html) would require each `CopyData` message to be split at the boundary of a record. The `COPY` protocol allows messages to be split at arbitrary points. [#69278][#69278]
- Fixed a bug where [`COPY FROM ... CSV`](../v21.1/copy-from.html) did not correctly handle octal byte escape sequences such as `\011` when using a [`BYTES` column](../v21.1/bytes.html). [#69278][#69278]
- Fixed an oversight in the data generator for TPC-H which was causing a smaller number of distinct values to be generated for p_type and p_container in the part table than the spec calls for. [#68710][#68710]
- Fixed a bug that was introduced in [v21.1.5](v21.1.html#v21-1-5), which prevented [nodes from being decommissioned](../v21.1/remove-nodes.html) in a cluster if the cluster had multiple nodes intermittently miss their liveness heartbeat. [#68552][#68552]
- Fixed a bug introduced in v21.1 where CockroachDB could return an internal error when performing streaming aggregation in some edge cases. [#69181][#69181]
- Fixed a bug that created non-partial unique constraints when a user attempted to create a partial unique constraint in [`ALTER TABLE` statements](../v21.1/alter-table.html). [#68745][#68745]
- Fixed a bug where a [`DROP VIEW ... CASCADE`](../v21.1/drop-view.html) could incorrectly result in "table ...is already being dropped" errors. [#68618][#68618]
- Fixed a bug introduced in v21.1 where the output of [`SHOW CREATE TABLE`](../v21.1/show-create.html) on tables with [hash-sharded indexes](../v21.1/hash-sharded-indexes.html) was not round-trippable. Executing the output would not create an identical table. This has been fixed by showing `CHECK` constraints that are automatically created for these indexes in the output of `SHOW CREATE TABLE`. [#69695][#69695]
- Fixed internal or "invalid cast" error in some cases involving cascading [updates](../v21.1/update.html). [#69180][#69180]
- Fixed a bug with cardinality estimation in the [optimizer](../v21.1/cost-based-optimizer.html) that was introduced in v21.1.0. This bug could cause inaccurate row count estimates in queries involving tables with a large number of null values. As a result, it was possible that the optimizer could choose a suboptimal plan. [#69125][#69125]
- Fixed a bug introduced in v20.2 that caused internal errors with set operations, like [`UNION`](../v21.1/selection-queries.html#union-combine-two-queries), and columns with tuple types that contained constant `NULL` values. [#69271][#69271]
- Added backwards compatibility between v21.1.x cluster versions and the [v21.1.8 cluster version](v21.1.html#v21-1-8). [#69894][#69894]
- Fixed a bug where table stats collection issued via [`EXPLAIN ANALYZE`](../v21.1/explain-analyze.html) statements or via [`CREATE STATISTICS`](../v21.1/create-statistics.html) statements without specifying the [`AS OF SYSTEM TIME`](../v21.1/as-of-system-time.html) option could run into `flow: memory budget exceeded`. [#69588][#69588]
- Fixed a bug where an internal error or a crash could occur when some [`crdb_internal` built-in functions](../v21.1/functions-and-operators.html) took string-like type arguments (e.g. `name`). [#69993][#69993]
- Fixed all broken links to the documentation from the DB Console. [#70117][#70117]
- Previously, when using [`ALTER PRIMARY KEY`](../v21.1/alter-primary-key.html) on a [`REGIONAL BY ROW`](../v21.1/multiregion-overview.html) table, the copied unique index from the old primary key would not have the correct [zone configurations](../v21.1/configure-zone.html) applied. This bug is now fixed. Users who have encountered this bug should re-create the index. [#69681][#69681]

<h3 id="v21-1-9-performance-improvements">Performance improvements</h3>

- Lookup joins on [partial indexes](../v21.1/partial-indexes.html) with [virtual computed columns](../v21.1/computed-columns.html) are not considered by the [optimizer](../v21.1/cost-based-optimizer.html), resulting in more efficient query plans in some cases. [#69110][#69110]
- Updated the [optimizer](../v21.1/cost-based-optimizer.html) cost model so that, all else being equal, the optimizer prefers plans in which [`LIMIT`](../v21.1/limit-offset.html) operators are pushed as far down the tree as possible. This can reduce the number of rows that need to be processed by higher operators in the plan tree, improving performance.[#69977][#69977]

<h3 id="v21-1-9-contributors">Contributors</h3>

This release includes 40 merged PRs by 19 authors.

[#68509]: https://github.com/cockroachdb/cockroach/pull/68509
[#68517]: https://github.com/cockroachdb/cockroach/pull/68517
[#68552]: https://github.com/cockroachdb/cockroach/pull/68552
[#68618]: https://github.com/cockroachdb/cockroach/pull/68618
[#68710]: https://github.com/cockroachdb/cockroach/pull/68710
[#68745]: https://github.com/cockroachdb/cockroach/pull/68745
[#69110]: https://github.com/cockroachdb/cockroach/pull/69110
[#69125]: https://github.com/cockroachdb/cockroach/pull/69125
[#69180]: https://github.com/cockroachdb/cockroach/pull/69180
[#69181]: https://github.com/cockroachdb/cockroach/pull/69181
[#69249]: https://github.com/cockroachdb/cockroach/pull/69249
[#69250]: https://github.com/cockroachdb/cockroach/pull/69250
[#69256]: https://github.com/cockroachdb/cockroach/pull/69256
[#69271]: https://github.com/cockroachdb/cockroach/pull/69271
[#69278]: https://github.com/cockroachdb/cockroach/pull/69278
[#69305]: https://github.com/cockroachdb/cockroach/pull/69305
[#69588]: https://github.com/cockroachdb/cockroach/pull/69588
[#69695]: https://github.com/cockroachdb/cockroach/pull/69695
[#69759]: https://github.com/cockroachdb/cockroach/pull/69759
[#69894]: https://github.com/cockroachdb/cockroach/pull/69894
[#69946]: https://github.com/cockroachdb/cockroach/pull/69946
[#69977]: https://github.com/cockroachdb/cockroach/pull/69977
[#69993]: https://github.com/cockroachdb/cockroach/pull/69993
[#70117]: https://github.com/cockroachdb/cockroach/pull/70117
[#69681]: https://github.com/cockroachdb/cockroach/pull/69681
[5c9ab2a9f]: https://github.com/cockroachdb/cockroach/commit/5c9ab2a9f
[df88282e3]: https://github.com/cockroachdb/cockroach/commit/df88282e3
